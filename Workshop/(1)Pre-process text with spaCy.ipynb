{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing texts with spaCy\n",
    "[spaCy](https://spacy.io/) is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython.  \n",
    "The features available are:\n",
    "* sentence segmentation\n",
    "* lemmatisation\n",
    "* tokenisation\n",
    "* POS Tagging\n",
    "* NER Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding a python executable with spaCy installed...\n",
      "spaCy (language model: en) is installed in more than one python\n",
      "spacyr will use /opt/conda/bin/python (because ask = FALSE)\n",
      "successfully initialized (spaCy Version: 2.2.3, language model: en)\n",
      "(python options: type = \"python_executable\", value = \"/opt/conda/bin/python\")\n"
     ]
    }
   ],
   "source": [
    "# library to use spaCy from R\n",
    "library(spacyr)\n",
    "\n",
    "# initialize spacy with a defined model\n",
    "spacyr::spacy_initialize(model = \"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import example texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @quotations vector of 6 movie quotations\n",
    "load(file = \"Data/quotations.RData\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run spaCy with function spacy_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'I\\'ve got a feeling we\\'re not in Kansas anymore.'"
      ],
      "text/latex": [
       "'I\\textbackslash{}'ve got a feeling we\\textbackslash{}'re not in Kansas anymore.'"
      ],
      "text/markdown": [
       "'I\\'ve got a feeling we\\'re not in Kansas anymore.'"
      ],
      "text/plain": [
       "[1] \"I've got a feeling we're not in Kansas anymore.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A spacyr_parsed: 12 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>doc_id</th><th scope=col>sentence_id</th><th scope=col>token_id</th><th scope=col>token</th><th scope=col>lemma</th><th scope=col>pos</th><th scope=col>entity</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>text1</td><td>1</td><td> 1</td><td>I      </td><td>-PRON- </td><td>PRON </td><td>     </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 2</td><td>'ve    </td><td>have   </td><td>AUX  </td><td>     </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 3</td><td>got    </td><td>get    </td><td>VERB </td><td>     </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 4</td><td>a      </td><td>a      </td><td>DET  </td><td>     </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 5</td><td>feeling</td><td>feeling</td><td>NOUN </td><td>     </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 6</td><td>we     </td><td>-PRON- </td><td>PRON </td><td>     </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 7</td><td>'re    </td><td>be     </td><td>AUX  </td><td>     </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 8</td><td>not    </td><td>not    </td><td>PART </td><td>     </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 9</td><td>in     </td><td>in     </td><td>ADP  </td><td>     </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>10</td><td>Kansas </td><td>Kansas </td><td>PROPN</td><td>GPE_B</td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>11</td><td>anymore</td><td>anymore</td><td>ADV  </td><td>     </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>12</td><td>.      </td><td>.      </td><td>PUNCT</td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spacyr\\_parsed: 12 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " doc\\_id & sentence\\_id & token\\_id & token & lemma & pos & entity\\\\\n",
       " <chr> & <int> & <int> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t text1 & 1 &  1 & I       & -PRON-  & PRON  &      \\\\\n",
       "\t text1 & 1 &  2 & 've     & have    & AUX   &      \\\\\n",
       "\t text1 & 1 &  3 & got     & get     & VERB  &      \\\\\n",
       "\t text1 & 1 &  4 & a       & a       & DET   &      \\\\\n",
       "\t text1 & 1 &  5 & feeling & feeling & NOUN  &      \\\\\n",
       "\t text1 & 1 &  6 & we      & -PRON-  & PRON  &      \\\\\n",
       "\t text1 & 1 &  7 & 're     & be      & AUX   &      \\\\\n",
       "\t text1 & 1 &  8 & not     & not     & PART  &      \\\\\n",
       "\t text1 & 1 &  9 & in      & in      & ADP   &      \\\\\n",
       "\t text1 & 1 & 10 & Kansas  & Kansas  & PROPN & GPE\\_B\\\\\n",
       "\t text1 & 1 & 11 & anymore & anymore & ADV   &      \\\\\n",
       "\t text1 & 1 & 12 & .       & .       & PUNCT &      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spacyr_parsed: 12 × 7\n",
       "\n",
       "| doc_id &lt;chr&gt; | sentence_id &lt;int&gt; | token_id &lt;int&gt; | token &lt;chr&gt; | lemma &lt;chr&gt; | pos &lt;chr&gt; | entity &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| text1 | 1 |  1 | I       | -PRON-  | PRON  | <!----> |\n",
       "| text1 | 1 |  2 | 've     | have    | AUX   | <!----> |\n",
       "| text1 | 1 |  3 | got     | get     | VERB  | <!----> |\n",
       "| text1 | 1 |  4 | a       | a       | DET   | <!----> |\n",
       "| text1 | 1 |  5 | feeling | feeling | NOUN  | <!----> |\n",
       "| text1 | 1 |  6 | we      | -PRON-  | PRON  | <!----> |\n",
       "| text1 | 1 |  7 | 're     | be      | AUX   | <!----> |\n",
       "| text1 | 1 |  8 | not     | not     | PART  | <!----> |\n",
       "| text1 | 1 |  9 | in      | in      | ADP   | <!----> |\n",
       "| text1 | 1 | 10 | Kansas  | Kansas  | PROPN | GPE_B |\n",
       "| text1 | 1 | 11 | anymore | anymore | ADV   | <!----> |\n",
       "| text1 | 1 | 12 | .       | .       | PUNCT | <!----> |\n",
       "\n"
      ],
      "text/plain": [
       "   doc_id sentence_id token_id token   lemma   pos   entity\n",
       "1  text1  1            1       I       -PRON-  PRON        \n",
       "2  text1  1            2       've     have    AUX         \n",
       "3  text1  1            3       got     get     VERB        \n",
       "4  text1  1            4       a       a       DET         \n",
       "5  text1  1            5       feeling feeling NOUN        \n",
       "6  text1  1            6       we      -PRON-  PRON        \n",
       "7  text1  1            7       're     be      AUX         \n",
       "8  text1  1            8       not     not     PART        \n",
       "9  text1  1            9       in      in      ADP         \n",
       "10 text1  1           10       Kansas  Kansas  PROPN GPE_B \n",
       "11 text1  1           11       anymore anymore ADV         \n",
       "12 text1  1           12       .       .       PUNCT       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quotations[1]\n",
    "spacy_parse(x = quotations[1], lemma = T, pos = T,entity = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Life is like a box of chocolates. You never know what you’re gonna get.'"
      ],
      "text/latex": [
       "'Life is like a box of chocolates. You never know what you’re gonna get.'"
      ],
      "text/markdown": [
       "'Life is like a box of chocolates. You never know what you’re gonna get.'"
      ],
      "text/plain": [
       "[1] \"Life is like a box of chocolates. You never know what you’re gonna get.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A spacyr_parsed: 18 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>doc_id</th><th scope=col>sentence_id</th><th scope=col>token_id</th><th scope=col>token</th><th scope=col>lemma</th><th scope=col>pos</th><th scope=col>entity</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>text1</td><td>1</td><td> 1</td><td>Life      </td><td>life     </td><td>NOUN </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 2</td><td>is        </td><td>be       </td><td>AUX  </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 3</td><td>like      </td><td>like     </td><td>SCONJ</td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 4</td><td>a         </td><td>a        </td><td>DET  </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 5</td><td>box       </td><td>box      </td><td>NOUN </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 6</td><td>of        </td><td>of       </td><td>ADP  </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 7</td><td>chocolates</td><td>chocolate</td><td>NOUN </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td> 8</td><td>.         </td><td>.        </td><td>PUNCT</td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>2</td><td> 1</td><td>You       </td><td>-PRON-   </td><td>PRON </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>2</td><td> 2</td><td>never     </td><td>never    </td><td>ADV  </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>2</td><td> 3</td><td>know      </td><td>know     </td><td>VERB </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>2</td><td> 4</td><td>what      </td><td>what     </td><td>PRON </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>2</td><td> 5</td><td>you       </td><td>-PRON-   </td><td>PRON </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>2</td><td> 6</td><td>’re       </td><td>be       </td><td>VERB </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>2</td><td> 7</td><td>gon       </td><td>go       </td><td>VERB </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>2</td><td> 8</td><td>na        </td><td>to       </td><td>PART </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>2</td><td> 9</td><td>get       </td><td>get      </td><td>AUX  </td><td></td></tr>\n",
       "\t<tr><td>text1</td><td>2</td><td>10</td><td>.         </td><td>.        </td><td>PUNCT</td><td></td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spacyr\\_parsed: 18 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " doc\\_id & sentence\\_id & token\\_id & token & lemma & pos & entity\\\\\n",
       " <chr> & <int> & <int> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t text1 & 1 &  1 & Life       & life      & NOUN  & \\\\\n",
       "\t text1 & 1 &  2 & is         & be        & AUX   & \\\\\n",
       "\t text1 & 1 &  3 & like       & like      & SCONJ & \\\\\n",
       "\t text1 & 1 &  4 & a          & a         & DET   & \\\\\n",
       "\t text1 & 1 &  5 & box        & box       & NOUN  & \\\\\n",
       "\t text1 & 1 &  6 & of         & of        & ADP   & \\\\\n",
       "\t text1 & 1 &  7 & chocolates & chocolate & NOUN  & \\\\\n",
       "\t text1 & 1 &  8 & .          & .         & PUNCT & \\\\\n",
       "\t text1 & 2 &  1 & You        & -PRON-    & PRON  & \\\\\n",
       "\t text1 & 2 &  2 & never      & never     & ADV   & \\\\\n",
       "\t text1 & 2 &  3 & know       & know      & VERB  & \\\\\n",
       "\t text1 & 2 &  4 & what       & what      & PRON  & \\\\\n",
       "\t text1 & 2 &  5 & you        & -PRON-    & PRON  & \\\\\n",
       "\t text1 & 2 &  6 & ’re        & be        & VERB  & \\\\\n",
       "\t text1 & 2 &  7 & gon        & go        & VERB  & \\\\\n",
       "\t text1 & 2 &  8 & na         & to        & PART  & \\\\\n",
       "\t text1 & 2 &  9 & get        & get       & AUX   & \\\\\n",
       "\t text1 & 2 & 10 & .          & .         & PUNCT & \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spacyr_parsed: 18 × 7\n",
       "\n",
       "| doc_id &lt;chr&gt; | sentence_id &lt;int&gt; | token_id &lt;int&gt; | token &lt;chr&gt; | lemma &lt;chr&gt; | pos &lt;chr&gt; | entity &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| text1 | 1 |  1 | Life       | life      | NOUN  | <!----> |\n",
       "| text1 | 1 |  2 | is         | be        | AUX   | <!----> |\n",
       "| text1 | 1 |  3 | like       | like      | SCONJ | <!----> |\n",
       "| text1 | 1 |  4 | a          | a         | DET   | <!----> |\n",
       "| text1 | 1 |  5 | box        | box       | NOUN  | <!----> |\n",
       "| text1 | 1 |  6 | of         | of        | ADP   | <!----> |\n",
       "| text1 | 1 |  7 | chocolates | chocolate | NOUN  | <!----> |\n",
       "| text1 | 1 |  8 | .          | .         | PUNCT | <!----> |\n",
       "| text1 | 2 |  1 | You        | -PRON-    | PRON  | <!----> |\n",
       "| text1 | 2 |  2 | never      | never     | ADV   | <!----> |\n",
       "| text1 | 2 |  3 | know       | know      | VERB  | <!----> |\n",
       "| text1 | 2 |  4 | what       | what      | PRON  | <!----> |\n",
       "| text1 | 2 |  5 | you        | -PRON-    | PRON  | <!----> |\n",
       "| text1 | 2 |  6 | ’re        | be        | VERB  | <!----> |\n",
       "| text1 | 2 |  7 | gon        | go        | VERB  | <!----> |\n",
       "| text1 | 2 |  8 | na         | to        | PART  | <!----> |\n",
       "| text1 | 2 |  9 | get        | get       | AUX   | <!----> |\n",
       "| text1 | 2 | 10 | .          | .         | PUNCT | <!----> |\n",
       "\n"
      ],
      "text/plain": [
       "   doc_id sentence_id token_id token      lemma     pos   entity\n",
       "1  text1  1            1       Life       life      NOUN        \n",
       "2  text1  1            2       is         be        AUX         \n",
       "3  text1  1            3       like       like      SCONJ       \n",
       "4  text1  1            4       a          a         DET         \n",
       "5  text1  1            5       box        box       NOUN        \n",
       "6  text1  1            6       of         of        ADP         \n",
       "7  text1  1            7       chocolates chocolate NOUN        \n",
       "8  text1  1            8       .          .         PUNCT       \n",
       "9  text1  2            1       You        -PRON-    PRON        \n",
       "10 text1  2            2       never      never     ADV         \n",
       "11 text1  2            3       know       know      VERB        \n",
       "12 text1  2            4       what       what      PRON        \n",
       "13 text1  2            5       you        -PRON-    PRON        \n",
       "14 text1  2            6       ’re        be        VERB        \n",
       "15 text1  2            7       gon        go        VERB        \n",
       "16 text1  2            8       na         to        PART        \n",
       "17 text1  2            9       get        get       AUX         \n",
       "18 text1  2           10       .          .         PUNCT       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quotations[2]\n",
    "spacy_parse(x = quotations[2], lemma = T, pos = T,entity = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'I am gonna kill Bill.'"
      ],
      "text/latex": [
       "'I am gonna kill Bill.'"
      ],
      "text/markdown": [
       "'I am gonna kill Bill.'"
      ],
      "text/plain": [
       "[1] \"I am gonna kill Bill.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A spacyr_parsed: 7 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>doc_id</th><th scope=col>sentence_id</th><th scope=col>token_id</th><th scope=col>token</th><th scope=col>lemma</th><th scope=col>pos</th><th scope=col>entity</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>text1</td><td>1</td><td>1</td><td>I   </td><td>-PRON-</td><td>PRON </td><td>        </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>2</td><td>am  </td><td>be    </td><td>AUX  </td><td>        </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>3</td><td>gon </td><td>go    </td><td>VERB </td><td>        </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>4</td><td>na  </td><td>to    </td><td>PART </td><td>        </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>5</td><td>kill</td><td>kill  </td><td>VERB </td><td>        </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>6</td><td>Bill</td><td>Bill  </td><td>PROPN</td><td>PERSON_B</td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>7</td><td>.   </td><td>.     </td><td>PUNCT</td><td>        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spacyr\\_parsed: 7 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " doc\\_id & sentence\\_id & token\\_id & token & lemma & pos & entity\\\\\n",
       " <chr> & <int> & <int> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t text1 & 1 & 1 & I    & -PRON- & PRON  &         \\\\\n",
       "\t text1 & 1 & 2 & am   & be     & AUX   &         \\\\\n",
       "\t text1 & 1 & 3 & gon  & go     & VERB  &         \\\\\n",
       "\t text1 & 1 & 4 & na   & to     & PART  &         \\\\\n",
       "\t text1 & 1 & 5 & kill & kill   & VERB  &         \\\\\n",
       "\t text1 & 1 & 6 & Bill & Bill   & PROPN & PERSON\\_B\\\\\n",
       "\t text1 & 1 & 7 & .    & .      & PUNCT &         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spacyr_parsed: 7 × 7\n",
       "\n",
       "| doc_id &lt;chr&gt; | sentence_id &lt;int&gt; | token_id &lt;int&gt; | token &lt;chr&gt; | lemma &lt;chr&gt; | pos &lt;chr&gt; | entity &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| text1 | 1 | 1 | I    | -PRON- | PRON  | <!----> |\n",
       "| text1 | 1 | 2 | am   | be     | AUX   | <!----> |\n",
       "| text1 | 1 | 3 | gon  | go     | VERB  | <!----> |\n",
       "| text1 | 1 | 4 | na   | to     | PART  | <!----> |\n",
       "| text1 | 1 | 5 | kill | kill   | VERB  | <!----> |\n",
       "| text1 | 1 | 6 | Bill | Bill   | PROPN | PERSON_B |\n",
       "| text1 | 1 | 7 | .    | .      | PUNCT | <!----> |\n",
       "\n"
      ],
      "text/plain": [
       "  doc_id sentence_id token_id token lemma  pos   entity  \n",
       "1 text1  1           1        I     -PRON- PRON          \n",
       "2 text1  1           2        am    be     AUX           \n",
       "3 text1  1           3        gon   go     VERB          \n",
       "4 text1  1           4        na    to     PART          \n",
       "5 text1  1           5        kill  kill   VERB          \n",
       "6 text1  1           6        Bill  Bill   PROPN PERSON_B\n",
       "7 text1  1           7        .     .      PUNCT         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quotations[3]\n",
    "spacy_parse(x = quotations[3], lemma = T, pos = T,entity = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process multiple texts at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A spacyr_parsed: 19 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>doc_id</th><th scope=col>sentence_id</th><th scope=col>token_id</th><th scope=col>token</th><th scope=col>lemma</th><th scope=col>pos</th><th scope=col>entity</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>text1</td><td>1</td><td>1</td><td>I     </td><td>-PRON-</td><td>PRON </td><td>        </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>2</td><td>am    </td><td>be    </td><td>AUX  </td><td>        </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>3</td><td>gon   </td><td>go    </td><td>VERB </td><td>        </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>4</td><td>na    </td><td>to    </td><td>PART </td><td>        </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>5</td><td>kill  </td><td>kill  </td><td>VERB </td><td>        </td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>6</td><td>Bill  </td><td>Bill  </td><td>PROPN</td><td>PERSON_B</td></tr>\n",
       "\t<tr><td>text1</td><td>1</td><td>7</td><td>.     </td><td>.     </td><td>PUNCT</td><td>        </td></tr>\n",
       "\t<tr><td>text2</td><td>1</td><td>1</td><td>You   </td><td>-PRON-</td><td>PRON </td><td>        </td></tr>\n",
       "\t<tr><td>text2</td><td>1</td><td>2</td><td>'re   </td><td>be    </td><td>AUX  </td><td>        </td></tr>\n",
       "\t<tr><td>text2</td><td>1</td><td>3</td><td>a     </td><td>a     </td><td>DET  </td><td>        </td></tr>\n",
       "\t<tr><td>text2</td><td>1</td><td>4</td><td>wizard</td><td>wizard</td><td>NOUN </td><td>        </td></tr>\n",
       "\t<tr><td>text2</td><td>1</td><td>5</td><td>,     </td><td>,     </td><td>PUNCT</td><td>        </td></tr>\n",
       "\t<tr><td>text2</td><td>1</td><td>6</td><td>Harry </td><td>Harry </td><td>PROPN</td><td>PERSON_B</td></tr>\n",
       "\t<tr><td>text2</td><td>1</td><td>7</td><td>.     </td><td>.     </td><td>PUNCT</td><td>        </td></tr>\n",
       "\t<tr><td>text3</td><td>1</td><td>1</td><td>You   </td><td>-PRON-</td><td>PRON </td><td>        </td></tr>\n",
       "\t<tr><td>text3</td><td>1</td><td>2</td><td>shall </td><td>shall </td><td>VERB </td><td>        </td></tr>\n",
       "\t<tr><td>text3</td><td>1</td><td>3</td><td>not   </td><td>not   </td><td>PART </td><td>        </td></tr>\n",
       "\t<tr><td>text3</td><td>1</td><td>4</td><td>pass  </td><td>pass  </td><td>VERB </td><td>        </td></tr>\n",
       "\t<tr><td>text3</td><td>1</td><td>5</td><td>.     </td><td>.     </td><td>PUNCT</td><td>        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spacyr\\_parsed: 19 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " doc\\_id & sentence\\_id & token\\_id & token & lemma & pos & entity\\\\\n",
       " <chr> & <int> & <int> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t text1 & 1 & 1 & I      & -PRON- & PRON  &         \\\\\n",
       "\t text1 & 1 & 2 & am     & be     & AUX   &         \\\\\n",
       "\t text1 & 1 & 3 & gon    & go     & VERB  &         \\\\\n",
       "\t text1 & 1 & 4 & na     & to     & PART  &         \\\\\n",
       "\t text1 & 1 & 5 & kill   & kill   & VERB  &         \\\\\n",
       "\t text1 & 1 & 6 & Bill   & Bill   & PROPN & PERSON\\_B\\\\\n",
       "\t text1 & 1 & 7 & .      & .      & PUNCT &         \\\\\n",
       "\t text2 & 1 & 1 & You    & -PRON- & PRON  &         \\\\\n",
       "\t text2 & 1 & 2 & 're    & be     & AUX   &         \\\\\n",
       "\t text2 & 1 & 3 & a      & a      & DET   &         \\\\\n",
       "\t text2 & 1 & 4 & wizard & wizard & NOUN  &         \\\\\n",
       "\t text2 & 1 & 5 & ,      & ,      & PUNCT &         \\\\\n",
       "\t text2 & 1 & 6 & Harry  & Harry  & PROPN & PERSON\\_B\\\\\n",
       "\t text2 & 1 & 7 & .      & .      & PUNCT &         \\\\\n",
       "\t text3 & 1 & 1 & You    & -PRON- & PRON  &         \\\\\n",
       "\t text3 & 1 & 2 & shall  & shall  & VERB  &         \\\\\n",
       "\t text3 & 1 & 3 & not    & not    & PART  &         \\\\\n",
       "\t text3 & 1 & 4 & pass   & pass   & VERB  &         \\\\\n",
       "\t text3 & 1 & 5 & .      & .      & PUNCT &         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spacyr_parsed: 19 × 7\n",
       "\n",
       "| doc_id &lt;chr&gt; | sentence_id &lt;int&gt; | token_id &lt;int&gt; | token &lt;chr&gt; | lemma &lt;chr&gt; | pos &lt;chr&gt; | entity &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| text1 | 1 | 1 | I      | -PRON- | PRON  | <!----> |\n",
       "| text1 | 1 | 2 | am     | be     | AUX   | <!----> |\n",
       "| text1 | 1 | 3 | gon    | go     | VERB  | <!----> |\n",
       "| text1 | 1 | 4 | na     | to     | PART  | <!----> |\n",
       "| text1 | 1 | 5 | kill   | kill   | VERB  | <!----> |\n",
       "| text1 | 1 | 6 | Bill   | Bill   | PROPN | PERSON_B |\n",
       "| text1 | 1 | 7 | .      | .      | PUNCT | <!----> |\n",
       "| text2 | 1 | 1 | You    | -PRON- | PRON  | <!----> |\n",
       "| text2 | 1 | 2 | 're    | be     | AUX   | <!----> |\n",
       "| text2 | 1 | 3 | a      | a      | DET   | <!----> |\n",
       "| text2 | 1 | 4 | wizard | wizard | NOUN  | <!----> |\n",
       "| text2 | 1 | 5 | ,      | ,      | PUNCT | <!----> |\n",
       "| text2 | 1 | 6 | Harry  | Harry  | PROPN | PERSON_B |\n",
       "| text2 | 1 | 7 | .      | .      | PUNCT | <!----> |\n",
       "| text3 | 1 | 1 | You    | -PRON- | PRON  | <!----> |\n",
       "| text3 | 1 | 2 | shall  | shall  | VERB  | <!----> |\n",
       "| text3 | 1 | 3 | not    | not    | PART  | <!----> |\n",
       "| text3 | 1 | 4 | pass   | pass   | VERB  | <!----> |\n",
       "| text3 | 1 | 5 | .      | .      | PUNCT | <!----> |\n",
       "\n"
      ],
      "text/plain": [
       "   doc_id sentence_id token_id token  lemma  pos   entity  \n",
       "1  text1  1           1        I      -PRON- PRON          \n",
       "2  text1  1           2        am     be     AUX           \n",
       "3  text1  1           3        gon    go     VERB          \n",
       "4  text1  1           4        na     to     PART          \n",
       "5  text1  1           5        kill   kill   VERB          \n",
       "6  text1  1           6        Bill   Bill   PROPN PERSON_B\n",
       "7  text1  1           7        .      .      PUNCT         \n",
       "8  text2  1           1        You    -PRON- PRON          \n",
       "9  text2  1           2        're    be     AUX           \n",
       "10 text2  1           3        a      a      DET           \n",
       "11 text2  1           4        wizard wizard NOUN          \n",
       "12 text2  1           5        ,      ,      PUNCT         \n",
       "13 text2  1           6        Harry  Harry  PROPN PERSON_B\n",
       "14 text2  1           7        .      .      PUNCT         \n",
       "15 text3  1           1        You    -PRON- PRON          \n",
       "16 text3  1           2        shall  shall  VERB          \n",
       "17 text3  1           3        not    not    PART          \n",
       "18 text3  1           4        pass   pass   VERB          \n",
       "19 text3  1           5        .      .      PUNCT         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy_parse(x = quotations[c(3,5,6)], lemma = T, pos = T, entity = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 3 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>doc_id</th><th scope=col>text</th><th scope=col>ent_type</th><th scope=col>start_id</th><th scope=col>length</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>text1</td><td>Kansas</td><td>GPE   </td><td>10</td><td>1</td></tr>\n",
       "\t<tr><td>text3</td><td>Bill  </td><td>PERSON</td><td> 6</td><td>1</td></tr>\n",
       "\t<tr><td>text5</td><td>Harry </td><td>PERSON</td><td> 6</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " doc\\_id & text & ent\\_type & start\\_id & length\\\\\n",
       " <chr> & <chr> & <chr> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t text1 & Kansas & GPE    & 10 & 1\\\\\n",
       "\t text3 & Bill   & PERSON &  6 & 1\\\\\n",
       "\t text5 & Harry  & PERSON &  6 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 5\n",
       "\n",
       "| doc_id &lt;chr&gt; | text &lt;chr&gt; | ent_type &lt;chr&gt; | start_id &lt;dbl&gt; | length &lt;int&gt; |\n",
       "|---|---|---|---|---|\n",
       "| text1 | Kansas | GPE    | 10 | 1 |\n",
       "| text3 | Bill   | PERSON |  6 | 1 |\n",
       "| text5 | Harry  | PERSON |  6 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  doc_id text   ent_type start_id length\n",
       "1 text1  Kansas GPE      10       1     \n",
       "2 text3  Bill   PERSON    6       1     \n",
       "3 text5  Harry  PERSON    6       1     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy_extract_entity(x = quotations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
